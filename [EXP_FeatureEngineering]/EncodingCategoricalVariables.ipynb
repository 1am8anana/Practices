{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ordinal encoding\n",
    "* Label encoding\n",
    "* One-hot encoding\n",
    "* Binary encoding\n",
    "* Hashing\n",
    "* Target encoding\n",
    "* Date-time encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollee_id                 int64\n",
      "city                       object\n",
      "city_development_index    float64\n",
      "gender                     object\n",
      "relevent_experience        object\n",
      "enrolled_university        object\n",
      "education_level            object\n",
      "major_discipline           object\n",
      "experience                 object\n",
      "company_size               object\n",
      "company_type               object\n",
      "last_new_job               object\n",
      "training_hours              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import pandas as pd\n",
    "\n",
    "# read csv file\n",
    "data = pd.read_csv(\"aug_test.csv\")\n",
    "\n",
    "# show variable types\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output features that are dtype = object and that tells us those features could be text or a mix of text and numerical values.\n",
    "\n",
    "The reason to spend time into this level of encoding is that there are many machine learning models that cannot handle text and will only work with numbers. Dataset must be encoded into numbers before begin to train, test, or evaluate a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graduate          1269\n",
      "Masters            496\n",
      "High School        222\n",
      "Phd                 54\n",
      "Primary School      36\n",
      "Name: education_level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"education_level\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is definitely an example of ordinal data: the education_level can easily be put in order of those in the “Phd” level to the education level in the “Primary School” level.\n",
    "\n",
    "The output printed the labels with the highest counts, assume the following hierarchy:\n",
    "* Phd\n",
    "* High School\n",
    "* Graduate\n",
    "* Masters\n",
    "* Primary School\n",
    "\n",
    "We need to convert these labels into numbers, and we can do this with two different approaches.\n",
    "\n",
    "First, we can do this by creating a dictionary where every label is the key and the new numeric number is the value. ‘Phd’ will get the highest score and ‘Primary School’ will be our lowest score. Then we will map each label from the education_level column to the numeric value and create a new column called education_rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    1269\n",
      "1.0     496\n",
      "3.0     222\n",
      "4.0      54\n",
      "0.0      36\n",
      "Name: education_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create dictionary of label: values in order\n",
    "rating_dict = {\"Phd\":4, \"High School\":3, \"Graduate\":2, \"Masters\":1, \"Primary School\":0}\n",
    "\n",
    "# create a new columns\n",
    "data[\"education_rating\"] = data[\"education_level\"].map(rating_dict)\n",
    "\n",
    "# show what diff\n",
    "print(data[\"education_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach we will show is how to utilize the <span style=\"color:green\">sklearn.preprocessing</span> library OrdinalEncoder. We follow a similar approach: we set our categories as a list, and then we will <span style=\"color:green\">.fit_transform</span> the values in our feature education_level. We need to make sure we adhere to the shape requirements of a 2-D array, so I’ll notice the method <span style=\"color:green\">.reshape(-1, 1)</span>.\n",
    "\n",
    "We’ll also note, this method will not work if feature has NaN values. Those need to be addressed prior to running <span style=\"color:green\">.fit_transform</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# show nan values in education_level\n",
    "print(data[\"education_level\"].isna().sum())\n",
    "\n",
    "# drop it\n",
    "new_df = data.dropna()\n",
    "print(new_df[\"education_level\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    697\n",
      "3.0    291\n",
      "0.0     31\n",
      "Name: education_rating_sklearn, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarza\\AppData\\Local\\Temp\\ipykernel_19212\\698263277.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[\"education_rating_sklearn\"] = encoder.fit_transform(education_reshaped)\n"
     ]
    }
   ],
   "source": [
    "# import sklearn lib\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# create encoder and set category order\n",
    "encoder = OrdinalEncoder(categories = [['Phd', 'High School', 'Graduate', 'Masters', 'Primary School']])\n",
    "\n",
    "# reshape feature\n",
    "education_reshaped = new_df[\"education_level\"].values.reshape(-1, 1)\n",
    "\n",
    "# create new variable with assigned (values)numbers\n",
    "new_df[\"education_rating_sklearn\"] = encoder.fit_transform(education_reshaped)\n",
    "\n",
    "# show what results\n",
    "print(new_df[\"education_rating_sklearn\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to talk about nominal data, and we have to approach this type of data differently than what we did with ordinal data. Our city feature has a lot of different labels, but here are the top five cities that appear in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "city_103    473\n",
      "city_21     318\n",
      "city_16     168\n",
      "city_114    155\n",
      "city_160    113\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"city\"].nunique())\n",
    "print(data['city'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to prepare this feature, we still need to convert our text to numbers, so let’s do just that. We will demonstrate two different approaches, with the first one showing how to convert the feature from an object type to a categories type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     473\n",
      "55    318\n",
      "41    168\n",
      "11    155\n",
      "42    113\n",
      "Name: city_codes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert feature to category type\n",
    "data[\"city_codes\"] = data[\"city\"].astype('category')\n",
    "\n",
    "# save new version of category codes\n",
    "data[\"city_codes\"] = data[\"city_codes\"].cat.codes\n",
    "\n",
    "# show to see transformation\n",
    "print(data[\"city_codes\"].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one more way we can transform this feature is by using <span style=\"color:green\">.sklearn.preprocessing</span> and the LabelEncoder library. This method will not work if your feature has NaN values. Those need to be addressed prior to running <span style=\"color:green\">.fit_transform</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     473\n",
      "55    318\n",
      "41    168\n",
      "11    155\n",
      "42    113\n",
      "Name: city_codes_sklearn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# import sklearn lib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# instantiate encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# create new varable with assigned (values)numbers\n",
    "data[\"city_codes_sklearn\"] = encoder.fit_transform(data[\"city\"])\n",
    "\n",
    "# show transformation\n",
    "print(data[\"city_codes_sklearn\"].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> One-hot Encoding\n",
    "\n",
    "One-hot encoding is when create a dummy variable for each value of categorical feature, and a dummy variable is defined as a numeric variable with two values: 0 and 1.\n",
    "\n",
    "this approach is great for categorical feature and will allow the model to see each category as its own feature and not try to create order between a value and a other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['enrollee_id', 'city', 'city_development_index', 'gender',\n",
      "       'relevent_experience', 'enrolled_university', 'education_level',\n",
      "       'major_discipline', 'experience', 'company_size',\n",
      "       ...\n",
      "       'city_84', 'city_89', 'city_9', 'city_90', 'city_91', 'city_93',\n",
      "       'city_94', 'city_97', 'city_98', 'city_99'],\n",
      "      dtype='object', length=124)\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import pandas as pd\n",
    "\n",
    "# use pandas .get_dummies to create new column for each city\n",
    "ohe = pd.get_dummies(data[\"city\"])\n",
    "\n",
    "# join the new columns back onto cars dataframe\n",
    "data = data.join(ohe)\n",
    "\n",
    "# show results\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a downside to this approach is that it can create a lot of features which can then create a very sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Binary Encoding\n",
    "\n",
    "Binary encoder will find the number of unique categories and then convert each category to its binary representation.\n",
    "\n",
    "ex: say we have unique 19 values and we want 5 digits long, so our binary encoder will need 5 columns to be able to represent all digits.\n",
    "some unique values has transformed to be represented in the binary form 10011. If we were to utilize this process instead of the traditional one-hot encoder we would have 5 numerical features instead of 19, reducing our features by about 75%!, that's make sense.\n",
    "\n",
    "to make this happen, we’ll use a library called <span style=\"color:green\">category_encoders</span> and import <span style=\"color:green\">BinaryEncoder</span>. We will determine which column to transform and set <span style=\"color:green\">drop_invariant</span> to True, so it will keep the five binary columns. If it is set to the default 0, then we would have an additional column full of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2129 entries, 0 to 2128\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   company_type_0  2129 non-null   int64\n",
      " 1   company_type_1  2129 non-null   int64\n",
      " 2   company_type_2  2129 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 50.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "# this will create a new data frame with the company_type column removed and replaced with 5 new binary features columns\n",
    "encoder = BinaryEncoder(cols = ['company_type'], drop_invariant = True)\n",
    "\n",
    "binary_results = encoder.fit_transform(data['company_type'])\n",
    "\n",
    "# show result\n",
    "print(binary_results.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Hashing\n",
    "\n",
    "Hashing is(another options) an encoding technique, this process is similar to one-hot encoding where it will create new binary columns, but within the parameters, you can decide how many features to output.\n",
    "A huge advantage is reduced dimensionality, but a large disadvantage is that some categories will be mapped to the same values. That is called collision.\n",
    "the Meaning of same hash values is, we’ve lost some information and our model won’t be able to see the difference between those.\n",
    "\n",
    "Here is how can make this work with Python. final result of <span style=\"color:green\">hash_results</span> will produce a data frame of just 5 columns, so we will want to concatenate this new data onto our original data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2129 entries, 0 to 2128\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   col_0   2129 non-null   int64\n",
      " 1   col_1   2129 non-null   int64\n",
      " 2   col_2   2129 non-null   int64\n",
      " 3   col_3   2129 non-null   int64\n",
      " 4   col_4   2129 non-null   int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 83.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "from category_encoders import HashingEncoder\n",
    "\n",
    "# instantiate encoder\n",
    "encoder = HashingEncoder(cols = 'company_type', n_components = 5)\n",
    "\n",
    "# fit transform on expect column and set to a new varable\n",
    "hash_results = encoder.fit_transform(data['company_type'])\n",
    "\n",
    "# show result\n",
    "print(hash_results.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when would I use this if I’m going to lose information and my model will see some other 'size company' combo with the same hash value as the same thing. Well, this could be a solution to your project and dataset if you are not as interested in assessing the impact of any particular categorical value.\n",
    "\n",
    "For this example, maybe you aren’t interested in knowing which 'size company' had an impact on your final prediction, but you want to be able to get the best performance from your model. This encoding solution may be a good approach.(end of hash encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Target Encoding\n",
    "\n",
    "Target encoding is a Bayesian encoder used to transform categorical features into hashed numerical values and is sometimes called the mean encoder. This encoder can be utilized for data sets that are being prepared for regression-based supervised learning, as it needs to take into consideration the mean of the target variable and its correlation between each individual category of our feature.\n",
    "\n",
    "It replaces each color with a blend of the mean price of that 'experience' and the mean 'training_hours' of all the data. Had it been predicting something categorical, it would’ve used a Bayesian target statistic.\n",
    "\n",
    "Some drawbacks to this approach are overfitting and unevenly distributed values that could lead to extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we are preparing our dataset for a regression-based supervised learning algorithm that is trying to predict the training hours(just for example 'experience' has some kind of relationship. 'training_hours')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experience\n",
      "0   64.522166\n",
      "1   65.110429\n",
      "2   67.327250\n",
      "3   67.798496\n",
      "4   67.945170\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# instantiate encoder\n",
    "encoder = TargetEncoder(cols = 'experience')\n",
    "\n",
    "# fit transform\n",
    "target_results = encoder.fit_transform(data['experience'], data['training_hours'])\n",
    "\n",
    "# show result\n",
    "print(target_results.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Date-time Encoding\n",
    "\n",
    "Exactly as its name suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "# see type of column that we want to convert to date-time object\n",
    "data = pd.read_csv(\"profile.csv\")\n",
    "print(data['became_member_on'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20170212\n",
      "1    20170715\n",
      "2    20180712\n",
      "3    20170509\n",
      "4    20170804\n",
      "Name: became_member_on, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['became_member_on'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 17000 entries, 0 to 16999\n",
      "Series name: became_member_on\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "17000 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 132.9 KB\n",
      "None\n",
      "0   1970-01-01 00:00:00.020170212\n",
      "1   1970-01-01 00:00:00.020170715\n",
      "2   1970-01-01 00:00:00.020180712\n",
      "Name: became_member_on, dtype: datetime64[ns] 0    1\n",
      "1    1\n",
      "2    1\n",
      "Name: month, dtype: int64 0    1\n",
      "1    1\n",
      "2    1\n",
      "Name: dayofweek, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# now we can convert it to date-time object\n",
    "data['became_member_on'] = pd.to_datetime(data['became_member_on'])\n",
    "print(data['became_member_on'].info())\n",
    "# complete to convert date-time objects\n",
    "\n",
    "\n",
    "# create new variable for month\n",
    "data['month'] = data['became_member_on'].dt.month\n",
    "\n",
    "# create new variable for day of the week\n",
    "data['dayofweek'] = data['became_member_on'].dt.day\n",
    "\n",
    "# show all result\n",
    "print(data['became_member_on'].head(3), data['month'].head(3), data['dayofweek'].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
