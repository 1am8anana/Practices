{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Logistic regression is a supervised machine learning algorithm that predicts the probability, ranging from 0 to 1, of a datapoint belonging to a specific category, or class. These probabilities can then be used to assign, or classify, observations to the more probable group.\n",
    "\n",
    "For example, we could use a logistic regression model to predict the probability that an incoming email is spam. If that probability is greater than 0.5, we could automatically send it to a spam folder. This is called binary classification because there are only two groups (eg., spam or not spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "We saw that predicted outcomes from a linear regression model range from negative to positive infinity. These predictions don’t really make sense for a classification problem. Step in logistic regression!\n",
    "\n",
    "To build a logistic regression model, we apply a logit link function to the left-hand side of our linear regression function. Remember the equation for a linear model looks like this:\n",
    "$$\\\\y = b_{0}+m_{1}x_{1}+m_{2}x_{2}+...+m_{n}x_{n}$$\n",
    "When we apply the logit function, we get the following:\n",
    "$$\\\\ln(y / 1 - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log-Odds\n",
    "\n",
    "So far, we’ve learned that the equation for a logistic regression model looks like this:\n",
    "$$\\\\ln(p / 1 - p)$$\n",
    "Note that we’ve replaced y with the letter p because we are going to interpret it as a probability (eg., the probability of a student passing the exam). The whole left-hand side of this equation is called log-odds because it is the natural logarithm (ln) of odds (p/(1-p)). The right-hand side of this equation looks exactly like regular linear regression!\n",
    "\n",
    "In order to understand how this link function works, let’s dig into the interpretation of log-odds a little more. The odds of an event occurring is:\n",
    "$$\\\\Odds = \\frac{p}{1 - p} = \\frac{P(event occurring)}{P(event not occurring)}\\$$\n",
    "\n",
    "For example, suppose that the probability a student passes an exam is 0.7. That means the probability of failing is 1 - 0.7 = 0.3. Thus, the odds of passing are:\n",
    "$$\\\\Odds of passing = \\frac{0.7}{1 - 0.7} = 2.33$$\n",
    "This means that students are 2.33 times more likely to pass than to fail.\n",
    "\n",
    "Odds can only be a positive number. When we take the natural log of odds (the log odds), we transform the odds from a positive value to a number between negative and positive infinity — which is exactly what we need! The logit function (log odds) transforms a probability (which is a number between 0 and 1) into a continuous value that can be positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
