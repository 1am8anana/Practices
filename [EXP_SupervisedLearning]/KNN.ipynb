{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a classification algorithm. The central idea is that data points with similar attributes tend to fall into similar categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the K-Nearest Neighbors algorithm, let’s first take a minute to think about an example.\n",
    "\n",
    "Consider a dataset of movies. Let’s brainstorm some features of a movie data point. A feature is a piece of information associated with a data point. Here are some potential features of movie data points:\n",
    "\n",
    "* the length of the movie in minutes.\n",
    "* the budget of a movie in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this movie is [minutes long, budget, not directed by Stanley Kubrick(False)]\n",
    "mean_girls = [97, 17000000, False]\n",
    "the_shining = [146, 19000000, True]\n",
    "gone_with_the_wind = [238, 3977000, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Between Points - 2D\n",
    "\n",
    "We were able to visualize the dataset and estimate the k nearest neighbors of an unknown point. But a computer isn’t going to be able to do that!\n",
    "\n",
    "We need to define what it means for two points to be close together or far apart. To do this, we’re going to use the Distance Formula:\n",
    "$$ \\sqrt{(A_{0}-B_{0})^2+(A_{1}-B_{1})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Between Points - 3D\n",
    "\n",
    "For example:\n",
    "\n",
    "Making a movie rating predictor based on just the length and release date of movies is pretty limited. There are so many more interesting pieces of data about movies that we could use! So let’s add another dimension.\n",
    "\n",
    "Let’s say this third dimension is the movie’s budget. We now have to find the distance between these two points in three dimensions.\n",
    "\n",
    "What if we’re not happy with just three dimensions? Unfortunately, it becomes pretty difficult to visualize points in dimensions higher than 3. But that doesn’t mean we can’t find the distance between them.\n",
    "\n",
    "The generalized distance formula between points A and B is as follows:\n",
    "$$ \\sqrt{(A_{0}-B_{0})^2+(A_{1}-B_{1})^2+...+(A_{n}-B_{n})^2} $$\n",
    "\n",
    "Using this formula, we can find the K-Nearest Neighbors of a point in N-dimensional space! We now can use as much information about our movies as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between Star Wars and Raiders: 7000000.000008286\n",
      "distance between Star Wars and Mean Girls: 6000000.000126083\n"
     ]
    }
   ],
   "source": [
    "star_wars = [125, 1977, 11000000]\n",
    "raiders = [115, 1981, 18000000]\n",
    "mean_girls = [97, 2004, 17000000]\n",
    "\n",
    "# distance function with any n-dimensions\n",
    "def distance(movie1, movie2):\n",
    "  squared_difference = 0.\n",
    "  for i in range(len(movie1)):\n",
    "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
    "  # out of loop\n",
    "  distance = squared_difference ** 0.5\n",
    "  return distance\n",
    "\n",
    "# print the new distance between Star Wars and Raiders\n",
    "print(f\"distance between Star Wars and Raiders: {distance(star_wars, raiders)}\")\n",
    "# print the new distance between Star Wars and Mean Girls\n",
    "print(f\"distance between Star Wars and Mean Girls: {distance(star_wars, mean_girls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data with Different Scales: Normalization\n",
    "\n",
    "We’ll implement the three steps of the K-Nearest Neighbor Algorithm:\n",
    "\n",
    "1. Normalize the data\n",
    "2. Find the k nearest neighbors\n",
    "3. Classify the new point based on those neighbors\n",
    "\n",
    "When we added the dimension of budget, you might have realized there are some problems with the way our data currently looks.\n",
    "\n",
    "Consider the two dimensions of release date and budget. The maximum difference between two movies’ release dates is about 125 years (The Lumière Brothers were making movies in the 1890s). However, the difference between two movies’ budget can be millions of dollars.\n",
    "\n",
    "The problem is that the distance formula treats all dimensions equally, regardless of their scale. If two movies came out 70 years apart, that should be a pretty big deal. However, right now, that’s exactly equivalent to two movies that have a difference in budget of 70 dollars. The difference in one year is exactly equal to the difference in one dollar of budget. That’s absurd!\n",
    "\n",
    "Another way of thinking about this is that the budget completely outweighs the importance of all other dimensions because it is on such a huge scale. The fact that two movies were 70 years apart is essentially meaningless compared to the difference in millions in the other dimension.\n",
    "\n",
    "The solution to this problem is to normalize the data so every value is between 0 and 1. In this case, we’re going to be using min-max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_dates = [1897, 1998, 2000, 1948, 1962, 1950, \n",
    "                 1975, 1960, 2017, 1937, 1968, 1996, \n",
    "                 1944, 1891, 1995, 1948, 2011, 1965, \n",
    "                 1891, 1978]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting list: [0.047619047619047616, 0.8492063492063492, 0.8650793650793651, 0.4523809523809524, 0.5634920634920635, 0.46825396825396826, 0.6666666666666666, 0.5476190476190477, 1.0, 0.36507936507936506, 0.6111111111111112, 0.8333333333333334, 0.42063492063492064, 0.0, 0.8253968253968254, 0.4523809523809524, 0.9523809523809523, 0.5873015873015873, 0.0, 0.6904761904761905]\n",
      "result of 1987: 0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "# create min-max normalization\n",
    "def min_max_normalize(lst):\n",
    "  minimum = min(lst)\n",
    "  maximum = max(lst)\n",
    "  normalized = []\n",
    "  for value in lst:\n",
    "    normalized_value = (value - minimum) / (maximum - minimum)\n",
    "    normalized.append(normalized_value)\n",
    "  return normalized\n",
    "  \n",
    "# call min-max normalize give the release_dates\n",
    "result_normalized = min_max_normalize(release_dates)\n",
    "# print the resulting list\n",
    "print(f\"resulting list: {result_normalized}\")\n",
    "# print the result of date 1897 after normalied\n",
    "print(f\"result of 1987: {result_normalized[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding the Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been normalized and we know how to find the distance between two points, we can begin classifying unknown data!\n",
    "\n",
    "To do this, we want to find the k nearest neighbors of the unclassified point.\n",
    "\n",
    "for now, let’s choose a number that seems somewhat reasonable. Let’s choose k = 5\n",
    "\n",
    "In order to find the 5 nearest neighbors, we need to compare this new unclassified movie to every other movie in the dataset. This means we’re going to be using the distance formula again and again. We ultimately want to end up with a sorted list of distances and the movies associated with those distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classify functions that has 3 parameters\n",
    "def classify(unknown, dataset, k):\n",
    "  distances = []\n",
    "  for title in dataset:\n",
    "    distance_to_point = distance(dataset[title], unknown)\n",
    "    distances.append([distance_to_point, title])\n",
    "  # sort the list by the distances(from smallest to largest)\n",
    "  distances.sort()\n",
    "  # k of nearest neighbors\n",
    "  neighbors = distances[0:k]\n",
    "  return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classify the new point based on those neighbors\n",
    "\n",
    "Count Neighbors\n",
    "\n",
    "We’ve now found the k nearest neighbors, and have stored them in a list\n",
    "\n",
    "Our goal now is to count the number of good movies and bad movies in the list of neighbors. If more of the neighbors were good, then the algorithm will classify the unknown movie as good. Otherwise, it will classify it as bad.\n",
    "\n",
    "What happens if there’s a tie. What if k = 8 and four neighbors were good and four neighbors were bad? There are different strategies, but one way to break the tie would be to choose the class of the closest point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our classify function now needs to have knowledge of the labels. Add a parameter named labels to classify. It should be the third parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels parmeters\n",
    "def classify(unknown, dataset, labels, k):\n",
    "  distances = []\n",
    "  #Looping through all points in the dataset\n",
    "  for title in dataset:\n",
    "    movie = dataset[title]\n",
    "    distance_to_point = distance(movie, unknown)\n",
    "    #Adding the distance and point associated with that distance\n",
    "    distances.append([distance_to_point, title])\n",
    "  distances.sort()\n",
    "  #Taking only the k closest points\n",
    "  neighbors = distances[0:k]\n",
    "\n",
    "  num_class1 = 0\n",
    "  num_class0 = 0\n",
    "  for movie in neighbors:\n",
    "    title = movie[1]\n",
    "    if labels[title] == 0:\n",
    "      num_class0 += 1\n",
    "    else:\n",
    "      num_class1 += 1\n",
    "  # classify our unknown movie\n",
    "  if num_class1 > num_class0:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can get classify data by calling the functions, before that we must normlize new data that we want to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Sets\n",
    "\n",
    "we’re not done yet. We now need to report how effective our algorithm is. After all, it’s possible our predictions are totally wrong!\n",
    "\n",
    "As with most machine learning algorithms, we have split our data into a training set and validation set.\n",
    "\n",
    "Once these sets are created, we will want to use every point in the validation set as input to the K Nearest Neighbor algorithm. We will take a movie from the validation set, compare it to all the movies in the training set, find the K Nearest Neighbors, and make a prediction. After making that prediction, we can then peek at the real answer (found in the validation labels) to see if our classifier got the answer correct.\n",
    "\n",
    "If we do this for every movie in the validation set, we can count the number of times the classifier got the answer right and the number of times it got it wrong. Using those two numbers, we can compute the validation accuracy.\n",
    "\n",
    "Validation accuracy will change depending on what K we use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: this code is not include dataset that means it cannot run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call classify functions to predict with k = 5\n",
    "guess = classify(validation_set[\"Bee Movie\"], training_set, training_labels, k = 5)\n",
    "# print the guess\n",
    "print(f\"the guess of Bee Movie is: {guess}\")\n",
    "\n",
    "# Let’s check to see if our classification got it right\n",
    "if guess == validation_labels[\"Bee Movie\"]:\n",
    "  print(\"classificatio of Bee Movie got Correct!\")\n",
    "else:\n",
    "  print(\"classificatio of Bee Movie got Wrong!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
